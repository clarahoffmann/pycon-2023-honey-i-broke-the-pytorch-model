{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from data_generation import MEANS, VARIANCES, KEY, generate_mv_data, NUM_SAMPLES\n",
    "from plot_utils import plot_scatter, plot_circles, plot_metrics\n",
    "from train_utils import SimpleDnn, Encoder, Linear_Encoder, create_loaders\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_circles\n",
    "import matplotlib.image as image\n",
    "from matplotlib.offsetbox import (OffsetImage, AnnotationBbox)\n",
    "import plotly.express as px\n",
    "from csv_utils import format_csv\n",
    "from pathlib import Path\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Data Example\n",
    "\n",
    "1. Generate linear data from three Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 15:27:27.888 | INFO     | train_utils:create_loaders:44 - Creating dataloaders with 80/20train/test split ðŸ”ª\n",
      "2023-04-03 15:27:27.889 | INFO     | train_utils:create_loaders:70 - Successfully created train and validation loader ðŸ¤—\n"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "data, labels = generate_mv_data(KEY, MEANS, VARIANCES, NUM_SAMPLES, 3)\n",
    "\n",
    "# format labels and set up dataloaders\n",
    "labels_one_hot = F.one_hot(torch.Tensor(np.hstack((np.array(labels)))).to(torch.int64), num_classes=3).float() \n",
    "data_linear = TensorDataset(\n",
    "                torch.Tensor(np.vstack((np.array(data)))), labels_one_hot\n",
    "            )\n",
    "train_loader_linear, val_loader_linear = create_loaders(data = data_linear, ratio = 0.8, num_workers = 0, shuffle_train = True, shuffle_val = False, batch_size = 32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train 'unbroken' model (simple feed-forward network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory metrics_csv/linear/version_0/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | encoder | Encoder       | 63    \n",
      "1 | f1      | BinaryF1Score | 0     \n",
      "------------------------------------------\n",
      "63        Trainable params\n",
      "0         Non-trainable params\n",
      "63        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/lightning_fabric/loggers/csv_logs.py:188: UserWarning: Experiment logs directory metrics_csv/linear/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 177.47it/s, v_num=0]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 173.16it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "# define model and logger\n",
    "simple_dnn = SimpleDnn(Encoder(input_dim = 2, output_dim = 3), task_type = 'classification')\n",
    "csv_logger = CSVLogger(save_dir='metrics_csv', name = 'linear')\n",
    "# train model on linear data\n",
    "trainer = pl.Trainer(logger=csv_logger, max_epochs = 50, log_every_n_steps=20)\n",
    "trainer.fit(model=simple_dnn, train_dataloaders = train_loader_linear, val_dataloaders = val_loader_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format, since csv logger captures metrics on step basis\n",
    "format_csv('metrics_csv/linear/version_0/metrics.csv', ['train_loss', 'val_loss'], Path('reformatted_metrics/linear_data.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Broken model: No activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory metrics_csv/linear_no_relu/version_0/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name    | Type           | Params\n",
      "-------------------------------------------\n",
      "0 | encoder | Linear_Encoder | 63    \n",
      "1 | f1      | BinaryF1Score  | 0     \n",
      "-------------------------------------------\n",
      "63        Trainable params\n",
      "0         Non-trainable params\n",
      "63        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/lightning_fabric/loggers/csv_logs.py:188: UserWarning: Experiment logs directory metrics_csv/linear_no_relu/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 152.62it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 149.26it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "# DNN without ReLUs\n",
    "simple_dnn_linear = SimpleDnn(Linear_Encoder(input_dim = 2, output_dim = 3), task_type = 'classification')\n",
    "csv_logger = CSVLogger(save_dir='metrics_csv', name = 'linear_no_relu')\n",
    "# train model on linear data\n",
    "trainer = pl.Trainer(logger=csv_logger, max_epochs = 50, log_every_n_steps=20)\n",
    "trainer.fit(model=simple_dnn_linear, train_dataloaders = train_loader_linear, val_dataloaders = val_loader_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format, since csv logger captures metrics on step basis\n",
    "format_csv('metrics_csv/linear_no_relu/version_0/metrics.csv', ['train_loss', 'val_loss'], Path('reformatted_metrics/linear_data_no_relu.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Data Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 16:07:27.043 | INFO     | train_utils:create_loaders:44 - Creating dataloaders with 80/20train/test split ðŸ”ª\n",
      "2023-04-03 16:07:27.044 | INFO     | train_utils:create_loaders:70 - Successfully created train and validation loader ðŸ¤—\n"
     ]
    }
   ],
   "source": [
    "data_circles, label_circles = make_circles(n_samples=NUM_SAMPLES, factor=0.5, noise=0.05)\n",
    "# concentric circles\n",
    "data_tensor_circles = TensorDataset(\n",
    "                torch.Tensor(data_circles), F.one_hot(torch.Tensor(label_circles).to(torch.int64), num_classes=2).float() \n",
    "            )\n",
    "train_loader_circles, val_loader_circles = create_loaders(data = data_tensor_circles, ratio = 0.8,  batch_size = 32, num_workers = 0,\n",
    "                                                        shuffle_train = True, shuffle_val = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train 'unbroken' model (simple feed-forward network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: metrics_csv/circles\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | encoder | Encoder       | 52    \n",
      "1 | f1      | BinaryF1Score | 0     \n",
      "------------------------------------------\n",
      "52        Trainable params\n",
      "0         Non-trainable params\n",
      "52        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 171.54it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 161.16it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "simple_dnn = SimpleDnn(Encoder(input_dim = 2, output_dim = 2), task_type = 'classification')\n",
    "csv_logger = CSVLogger(save_dir='metrics_csv', name = 'circles')\n",
    "# train model on nonlinear data\n",
    "trainer = pl.Trainer(logger=csv_logger, max_epochs = 50)\n",
    "trainer.fit(model=simple_dnn, train_dataloaders = train_loader_circles, val_dataloaders = val_loader_circles)\n",
    "format_csv('metrics_csv/circles/version_0/metrics.csv', ['train_loss', 'val_loss'], Path('reformatted_metrics/circle_data.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Broken model: No activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: metrics_csv/circles_no_relu\n",
      "\n",
      "  | Name    | Type           | Params\n",
      "-------------------------------------------\n",
      "0 | encoder | Linear_Encoder | 52    \n",
      "1 | f1      | BinaryF1Score  | 0     \n",
      "-------------------------------------------\n",
      "52        Trainable params\n",
      "0         Non-trainable params\n",
      "52        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 142.19it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 132.34it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "# DNN without ReLUs\n",
    "simple_dnn_linear = SimpleDnn(Linear_Encoder(input_dim = 2, output_dim = 2), task_type = 'classification')\n",
    "# train model on nonlinear data\n",
    "csv_logger = CSVLogger(save_dir='metrics_csv', name = 'circles_no_relu')\n",
    "trainer = pl.Trainer(logger=csv_logger, max_epochs = 50)\n",
    "trainer.fit(model=simple_dnn_linear, train_dataloaders = train_loader_circles, val_dataloaders = val_loader_circles)\n",
    "format_csv('metrics_csv/circles_no_relu/version_0/metrics.csv', ['train_loss', 'val_loss'], Path('reformatted_metrics/circle_data_no_relu.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Broken model: Frozen weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory metrics_csv/circles_frozen/version_0/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | encoder | Encoder       | 52    \n",
      "1 | f1      | BinaryF1Score | 0     \n",
      "------------------------------------------\n",
      "30        Trainable params\n",
      "22        Non-trainable params\n",
      "52        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/lightning_fabric/loggers/csv_logs.py:188: UserWarning: Experiment logs directory metrics_csv/circles_frozen/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 127.32it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 120.24it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "simple_dnn = SimpleDnn(Encoder(input_dim = 2, output_dim = 2), task_type = 'classification')\n",
    "\n",
    "num_params = len([param for param in simple_dnn.parameters()])\n",
    "for i, param in zip(range(num_params), simple_dnn.parameters()):\n",
    "    if i in [num_params-1, num_params -2] :\n",
    "        param.requires_grad = False\n",
    "\n",
    "csv_logger = CSVLogger(save_dir='metrics_csv', name = 'circles_frozen')\n",
    "# train model on nonlinear data\n",
    "trainer = pl.Trainer(logger=csv_logger, max_epochs = 50)\n",
    "trainer.fit(model=simple_dnn, train_dataloaders = train_loader_circles, val_dataloaders = val_loader_circles)\n",
    "format_csv('metrics_csv/circles_frozen/version_0/metrics.csv', ['train_loss', 'val_loss'], Path('reformatted_metrics/circle_data_frozen.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Broken model: Frozen Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory metrics_csv/circles_frozen_bias/version_0/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | encoder | Encoder       | 52    \n",
      "1 | f1      | BinaryF1Score | 0     \n",
      "------------------------------------------\n",
      "50        Trainable params\n",
      "2         Non-trainable params\n",
      "52        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/lightning_fabric/loggers/csv_logs.py:188: UserWarning: Experiment logs directory metrics_csv/circles_frozen_bias/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 56.09it/s, v_num=0] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 53.67it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "simple_dnn = SimpleDnn(Encoder(input_dim = 2, output_dim = 2), task_type = 'classification')\n",
    "\n",
    "num_params = len([param for param in simple_dnn.parameters()])\n",
    "for i, param in zip(range(num_params), simple_dnn.parameters()):\n",
    "    if i == num_params-1 :\n",
    "        param.requires_grad = False\n",
    "\n",
    "csv_logger = CSVLogger(save_dir='metrics_csv', name = 'circles_frozen_bias')\n",
    "# train model on nonlinear data\n",
    "trainer = pl.Trainer(logger=csv_logger, max_epochs = 50)\n",
    "trainer.fit(model=simple_dnn, train_dataloaders = train_loader_circles, val_dataloaders = val_loader_circles)\n",
    "format_csv('metrics_csv/circles_frozen_bias/version_0/metrics.csv', ['train_loss', 'val_loss'], Path('reformatted_metrics/circle_data_frozen_bias.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Broken model: Trainloader returns single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 16:07:34.987 | INFO     | train_utils:create_loaders:44 - Creating dataloaders with 80/20train/test split ðŸ”ª\n",
      "2023-04-03 16:07:34.994 | INFO     | train_utils:create_loaders:70 - Successfully created train and validation loader ðŸ¤—\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory metrics_csv/circles_dataloader_broken/version_0/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | encoder | Encoder       | 52    \n",
      "1 | f1      | BinaryF1Score | 0     \n",
      "------------------------------------------\n",
      "52        Trainable params\n",
      "0         Non-trainable params\n",
      "52        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/lightning_fabric/loggers/csv_logs.py:188: UserWarning: Experiment logs directory metrics_csv/circles_dataloader_broken/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/clarahoffmann/Documents/code/pycon_2023_honey_i_broke_the_pytorch_model/.venv/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 85.10it/s, v_num=0] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 78.01it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "simple_dnn = SimpleDnn(Encoder(input_dim = 2, output_dim = 2), task_type = 'classification')\n",
    "train_loader_circles_broken, val_loader_circles = create_loaders(data = data_tensor_circles, ratio = 0.8,  batch_size = 32, num_workers = 0,\n",
    "                                                        shuffle_train = True, shuffle_val = False, subset_broken_train = True)\n",
    "\n",
    "csv_logger = CSVLogger(save_dir='metrics_csv', name = 'circles_dataloader_broken')\n",
    "# train model on nonlinear data\n",
    "trainer = pl.Trainer(logger=csv_logger, max_epochs = 50)\n",
    "trainer.fit(model=simple_dnn, train_dataloaders = train_loader_circles_broken, val_dataloaders = val_loader_circles)\n",
    "format_csv('metrics_csv/circles_dataloader_broken/version_0/metrics.csv', ['train_loss', 'val_loss'], Path('reformatted_metrics/circle_dataloader_broken.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>metric</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.664477</td>\n",
       "      <td>train_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>0.292344</td>\n",
       "      <td>train_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.376060</td>\n",
       "      <td>train_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.709956</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.709790</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.709714</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.709719</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0.709794</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0.709931</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>0.710121</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>0.710627</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>0.710928</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>0.711256</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11</td>\n",
       "      <td>0.711608</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>0.711988</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>0.712401</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>0.712851</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15</td>\n",
       "      <td>0.713347</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16</td>\n",
       "      <td>0.713899</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17</td>\n",
       "      <td>0.714516</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>18</td>\n",
       "      <td>0.715209</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19</td>\n",
       "      <td>0.715990</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20</td>\n",
       "      <td>0.716870</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21</td>\n",
       "      <td>0.717858</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>22</td>\n",
       "      <td>0.718967</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23</td>\n",
       "      <td>0.720207</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24</td>\n",
       "      <td>0.721592</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>25</td>\n",
       "      <td>0.723133</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>26</td>\n",
       "      <td>0.724846</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>27</td>\n",
       "      <td>0.726743</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>28</td>\n",
       "      <td>0.728838</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>29</td>\n",
       "      <td>0.731144</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>30</td>\n",
       "      <td>0.733673</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>31</td>\n",
       "      <td>0.736449</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>32</td>\n",
       "      <td>0.739484</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>33</td>\n",
       "      <td>0.742793</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>34</td>\n",
       "      <td>0.746390</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>35</td>\n",
       "      <td>0.750294</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>36</td>\n",
       "      <td>0.754520</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>37</td>\n",
       "      <td>0.759098</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>38</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>39</td>\n",
       "      <td>0.769364</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>40</td>\n",
       "      <td>0.775067</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>41</td>\n",
       "      <td>0.781167</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>42</td>\n",
       "      <td>0.787676</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>43</td>\n",
       "      <td>0.794604</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>44</td>\n",
       "      <td>0.801960</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>45</td>\n",
       "      <td>0.809768</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>46</td>\n",
       "      <td>0.818023</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>47</td>\n",
       "      <td>0.826737</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>48</td>\n",
       "      <td>0.835920</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>49</td>\n",
       "      <td>0.845564</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch    metric       label\n",
       "0       7  0.664477  train_loss\n",
       "1      28  0.292344  train_loss\n",
       "2      49 -0.376060  train_loss\n",
       "3       0  0.709956    val_loss\n",
       "4       1  0.709790    val_loss\n",
       "5       2  0.709714    val_loss\n",
       "6       3  0.709719    val_loss\n",
       "7       4  0.709794    val_loss\n",
       "8       5  0.709931    val_loss\n",
       "9       6  0.710121    val_loss\n",
       "10      7  0.710357    val_loss\n",
       "11      8  0.710627    val_loss\n",
       "12      9  0.710928    val_loss\n",
       "13     10  0.711256    val_loss\n",
       "14     11  0.711608    val_loss\n",
       "15     12  0.711988    val_loss\n",
       "16     13  0.712401    val_loss\n",
       "17     14  0.712851    val_loss\n",
       "18     15  0.713347    val_loss\n",
       "19     16  0.713899    val_loss\n",
       "20     17  0.714516    val_loss\n",
       "21     18  0.715209    val_loss\n",
       "22     19  0.715990    val_loss\n",
       "23     20  0.716870    val_loss\n",
       "24     21  0.717858    val_loss\n",
       "25     22  0.718967    val_loss\n",
       "26     23  0.720207    val_loss\n",
       "27     24  0.721592    val_loss\n",
       "28     25  0.723133    val_loss\n",
       "29     26  0.724846    val_loss\n",
       "30     27  0.726743    val_loss\n",
       "31     28  0.728838    val_loss\n",
       "32     29  0.731144    val_loss\n",
       "33     30  0.733673    val_loss\n",
       "34     31  0.736449    val_loss\n",
       "35     32  0.739484    val_loss\n",
       "36     33  0.742793    val_loss\n",
       "37     34  0.746390    val_loss\n",
       "38     35  0.750294    val_loss\n",
       "39     36  0.754520    val_loss\n",
       "40     37  0.759098    val_loss\n",
       "41     38  0.764045    val_loss\n",
       "42     39  0.769364    val_loss\n",
       "43     40  0.775067    val_loss\n",
       "44     41  0.781167    val_loss\n",
       "45     42  0.787676    val_loss\n",
       "46     43  0.794604    val_loss\n",
       "47     44  0.801960    val_loss\n",
       "48     45  0.809768    val_loss\n",
       "49     46  0.818023    val_loss\n",
       "50     47  0.826737    val_loss\n",
       "51     48  0.835920    val_loss\n",
       "52     49  0.845564    val_loss"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('reformatted_metrics/circle_dataloader_broken.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor_circles[0:5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
